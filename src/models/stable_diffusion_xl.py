from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl import StableDiffusionXLPipeline
import torch
from src.models.base_model import BaseModel

class StableDiffusionXLModel(BaseModel):
    """
    Stable Diffusion XL æ¨¡å‹
    """
    def __init__(self):
        super().__init__("stable_diffusion_xl")
        self.model_id = "stabilityai/stable-diffusion-xl-base-1.0"
    
    def load_pipeline(self):
        """è¼‰å…¥æ¨¡å‹ç®¡é“ (Mac M1 MPS è¨˜æ†¶é«”å„ªåŒ–ç‰ˆ)"""
        print(f"ğŸ”„ åŠ è¼‰ {self.model_name} æ¨¡å‹...")
        
        # Mac M1 MPS è¨˜æ†¶é«”å„ªåŒ–è¨­å®š
        if self.device == "mps":
            print("ğŸ Mac M1 MPS è¨˜æ†¶é«”å„ªåŒ–æ¨¡å¼")
            # ä½¿ç”¨ float32 æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨
            torch_dtype = torch.float32
            variant = None
        else:
            torch_dtype = torch.float16 if self.device == "cuda" else torch.float32
            variant = "fp16" if self.device == "cuda" else None
        
        # è¼‰å…¥æ¨¡å‹
        pipe = StableDiffusionXLPipeline.from_pretrained(
            self.model_id,
            torch_dtype=torch_dtype,
            use_safetensors=True,
            variant=variant,
            # Mac M1 å°ˆç”¨ï¼šä½è¨˜æ†¶é«”æ¨¡å¼
            low_cpu_mem_usage=True if self.device == "mps" else False
        )
        
        # å„ªåŒ–ç®¡é“
        pipe = self.optimize_pipeline(pipe)
        
        return pipe