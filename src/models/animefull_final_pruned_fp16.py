from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion import StableDiffusionPipeline
import torch
import os
from src.models.base_model import BaseModel

class AnimefullFinalPrunedFp16Model(BaseModel):
    """
    AnimefullFinalPrunedFp16 æ¨¡å‹
    åŸºæ–¼ Stable Diffusion v1.5ï¼Œä¸¦åŠ è¼‰ animefull-final-pruned-fp16.safetensors æ¬Šé‡
    """
    def __init__(self):
        super().__init__("animefull_final_pruned_fp16")
        self.base_model_id = "runwayml/stable-diffusion-v1-5"
        self.weights_file = self._get_weights_file_path()
    
    def _get_weights_file_path(self):
        """ç²å–æ¬Šé‡æ–‡ä»¶è·¯å¾‘"""
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        return os.path.join(base_dir, "assets", "models", "animefull-final-pruned-fp16.safetensors")
    
    def load_pipeline(self):
        """è¼‰å…¥æ¨¡å‹ç®¡é“"""
        print(f"ğŸ”„ åŠ è¼‰åŸºç¤æ¨¡å‹ {self.base_model_id}...")
        
        # è¼‰å…¥åŸºç¤æ¨¡å‹
        pipe = StableDiffusionPipeline.from_pretrained(
            self.base_model_id,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        
        # å„ªåŒ–ç®¡é“
        pipe = self.optimize_pipeline(pipe)
        
        # å˜—è©¦åŠ è¼‰è‡ªå®šç¾©æ¬Šé‡
        pipe = self._merge_custom_weights(pipe)
        
        return pipe
    
    def _merge_custom_weights(self, pipe):
        """åˆä½µè‡ªå®šç¾©æ¬Šé‡åˆ°æ¨¡å‹ä¸­"""
        if not os.path.exists(self.weights_file):
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ¬Šé‡æ–‡ä»¶: {self.weights_file}")
            print(f"ç¹¼çºŒä½¿ç”¨åŸºç¤æ¨¡å‹ {self.base_model_id}")
            return pipe
        
        try:
            print(f"ğŸ”„ åˆä½µ animefull-final-pruned-fp16 æ¬Šé‡åˆ°åŸºç¤æ¨¡å‹...")
            
            # ä½¿ç”¨ safetensors åº«åŠ è¼‰æ¬Šé‡
            try:
                from safetensors import safe_open
            except ImportError:
                print("âš ï¸ æœªå®‰è£ safetensors åº«ï¼Œç„¡æ³•åŠ è¼‰è‡ªå®šç¾©æ¬Šé‡")
                return pipe
            
            # åŠ è¼‰æ‰€æœ‰æ¬Šé‡
            all_weights = self._load_all_weights(self.weights_file)
            if not all_weights:
                return pipe
            
            # å°‡æ¬Šé‡æ‡‰ç”¨åˆ°æ¨¡å‹çš„ä¸åŒçµ„ä»¶
            pipe = self._apply_weights_to_components(pipe, all_weights)
            
            print(f"âœ… æˆåŠŸåˆä½µ animefull-final-pruned-fp16 æ¬Šé‡")
            
        except Exception as e:
            print(f"âš ï¸ åˆä½µæ¬Šé‡å¤±æ•—: {e}")
            print(f"ç¹¼çºŒä½¿ç”¨åŸºç¤æ¨¡å‹ {self.base_model_id}")
        
        return pipe
    
    def _load_all_weights(self, weights_file):
        """åŠ è¼‰æ‰€æœ‰æ¬Šé‡"""
        all_weights = {}
        
        try:
            # ç¢ºä¿ safetensors åº«å·²å°å…¥
            from safetensors import safe_open
            
            with safe_open(weights_file, framework="pt") as f:
                keys = f.keys()
                
                # åŠ è¼‰æ‰€æœ‰æ¬Šé‡
                for k in keys:
                    try:
                        all_weights[k] = f.get_tensor(k)
                    except Exception as e:
                        print(f"âš ï¸ ç„¡æ³•åŠ è¼‰æ¬Šé‡ {k}: {e}")
            
            return all_weights
        except Exception as e:
            print(f"âš ï¸ åŠ è¼‰æ¬Šé‡æ–‡ä»¶å¤±æ•—: {e}")
            return {}
    
    def _apply_weights_to_components(self, pipe, all_weights):
        """å°‡æ¬Šé‡æ‡‰ç”¨åˆ°æ¨¡å‹çš„ä¸åŒçµ„ä»¶"""
        if not all_weights:
            return pipe
        
        keys = list(all_weights.keys())
        
        # æ‡‰ç”¨ UNet æ¬Šé‡
        self._apply_unet_weights(pipe, all_weights, keys)
        
        # æ‡‰ç”¨ VAE æ¬Šé‡
        self._apply_vae_weights(pipe, all_weights, keys)
        
        # æ‡‰ç”¨ Text Encoder æ¬Šé‡
        self._apply_text_encoder_weights(pipe, all_weights, keys)
        
        # æ‡‰ç”¨ Scheduler æ¬Šé‡
        self._apply_scheduler_weights(pipe, all_weights, keys)
        
        # æ‡‰ç”¨å…¶ä»–æ¬Šé‡
        self._apply_other_weights(pipe, all_weights, keys)
        
        return pipe
    
    def _apply_unet_weights(self, pipe, all_weights, keys):
        """æ‡‰ç”¨ UNet æ¬Šé‡"""
        unet_keys = [k for k in keys if k.startswith("unet") or k.startswith("model.diffusion_model")]
        if unet_keys:
            unet_state_dict = {k: all_weights[k] for k in unet_keys}
            pipe.unet.load_state_dict(unet_state_dict, strict=False)
    
    def _apply_vae_weights(self, pipe, all_weights, keys):
        """æ‡‰ç”¨ VAE æ¬Šé‡"""
        vae_keys = [k for k in keys if k.startswith("vae") or k.startswith("first_stage_model")]
        if vae_keys:
            vae_state_dict = {k: all_weights[k] for k in vae_keys}
            pipe.vae.load_state_dict(vae_state_dict, strict=False)
    
    def _apply_text_encoder_weights(self, pipe, all_weights, keys):
        """æ‡‰ç”¨ Text Encoder æ¬Šé‡"""
        text_encoder_keys = [k for k in keys if k.startswith("text_encoder") or k.startswith("cond_stage_model")]
        if text_encoder_keys:
            text_encoder_state_dict = {k: all_weights[k] for k in text_encoder_keys}
            pipe.text_encoder.load_state_dict(text_encoder_state_dict, strict=False)
    
    def _apply_scheduler_weights(self, pipe, all_weights, keys):
        """æ‡‰ç”¨ Scheduler æ¬Šé‡"""
        scheduler_keys = [
            'alphas_cumprod', 'alphas_cumprod_prev', 'betas',
            'log_one_minus_alphas_cumprod', 'posterior_log_variance_clipped',
            'posterior_mean_coef1', 'posterior_mean_coef2', 'posterior_variance',
            'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod',
            'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod'
        ]
        
        found_scheduler_keys = [k for k in keys if k in scheduler_keys]
        if found_scheduler_keys and hasattr(pipe, 'scheduler'):
            try:
                for k in found_scheduler_keys:
                    if hasattr(pipe.scheduler, k):
                        setattr(pipe.scheduler, k, all_weights[k].to(self.device))
                
                # é‡æ–°è¨ˆç®—æ™‚é–“æ­¥é•·
                if hasattr(pipe.scheduler, 'set_timesteps') and hasattr(pipe.scheduler, 'num_inference_steps'):
                    if pipe.scheduler.num_inference_steps is not None:
                        pipe.scheduler.set_timesteps(pipe.scheduler.num_inference_steps)
            except Exception as e:
                print(f"âš ï¸ æ›´æ–° scheduler åƒæ•¸å¤±æ•—: {e}")
    
    def _apply_other_weights(self, pipe, all_weights, keys):
        """æ‡‰ç”¨å…¶ä»–æ¬Šé‡"""
        # å·²è™•ç†çš„éµ
        processed_keys = []
        processed_keys.extend([k for k in keys if k.startswith("unet") or k.startswith("model.diffusion_model")])
        processed_keys.extend([k for k in keys if k.startswith("vae") or k.startswith("first_stage_model")])
        processed_keys.extend([k for k in keys if k.startswith("text_encoder") or k.startswith("cond_stage_model")])
        processed_keys.extend([k for k in keys if k in [
            'alphas_cumprod', 'alphas_cumprod_prev', 'betas',
            'log_one_minus_alphas_cumprod', 'posterior_log_variance_clipped',
            'posterior_mean_coef1', 'posterior_mean_coef2', 'posterior_variance',
            'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod',
            'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod'
        ]])
        
        # æœªè™•ç†çš„éµ
        other_keys = [k for k in keys if k not in processed_keys]
        
        # å˜—è©¦å°‡é€™äº›éµæ‡‰ç”¨åˆ°æ¨¡å‹çš„å…¶ä»–çµ„ä»¶
        if other_keys:
            for component_name in dir(pipe):
                # è·³éç§æœ‰å±¬æ€§å’Œæ–¹æ³•
                if component_name.startswith('_'):
                    continue
                    
                try:
                    component = getattr(pipe, component_name)
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºå¯è¼‰å…¥æ¬Šé‡çš„çµ„ä»¶
                    if hasattr(component, 'load_state_dict'):
                        try:
                            # å‰µå»ºä¸€å€‹åªåŒ…å«èˆ‡è©²çµ„ä»¶ç›¸é—œçš„éµçš„å­—å…¸
                            component_dict = {}
                            for k in other_keys:
                                if k.startswith(component_name):
                                    component_dict[k] = all_weights[k]
                            
                            if component_dict:
                                component.load_state_dict(component_dict, strict=False)
                        except Exception:
                            pass
                except Exception:
                    pass