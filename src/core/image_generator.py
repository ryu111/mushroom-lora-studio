"""
åœ–åƒç”Ÿæˆæ¨¡å¡Š
ç”¨æ–¼ç”Ÿæˆå’Œè™•ç†åœ–åƒ
(æœ€çµ‚åµéŒ¯ä¿®æ­£ç‰ˆ)
"""
import sys
import os
import torch
# from rembg import remove  <--- [æœ€çµ‚ä¿®æ­£] å¾é ‚éƒ¨ç§»é™¤ï¼
from PIL import Image
import time
import numpy as np
from io import BytesIO
import gc

print("--- [ImageGenerator] æ¨¡å¡Šé–‹å§‹è¢«å°å…¥... ---", flush=True)

class ImageGenerator:
    # é¡åˆ¥è®Šæ•¸ï¼šå…±äº« rembg æ¨¡å‹ï¼Œé¿å…é‡è¤‡è¼‰å…¥
    _rembg_session = None
    
    # __init__ å’Œå…¶ä»–æ–¹æ³•ä¿æŒä¸è®Š...
    def __init__(self, config, pipe, weight_name):
        print("--- [ImageGenerator] __init__ é–‹å§‹åŸ·è¡Œ... ---", flush=True)
        self.config = config
        self.pipe = pipe
        self.weight_name = weight_name
        self.prompt = config.get('prompt_template', '')
        self.negative_prompt = config.get('negative_prompt', '')
        self.action_key = "standing"
        self.expression_key = "smiling"
        image_size = config.get('image_size', {})
        self.height = image_size.get('height', 512)
        self.width = image_size.get('width', 512)
        parameters = config.get('parameters', {})
        self.guidance_scale = parameters.get('guidance_scale', 7.5)
        self.strength = parameters.get('strength', 0.75)
        self.noise_level = parameters.get('noise_level', 0.0)
        self.original_image, self.original_image_name = self._load_original_image()
        print("--- [ImageGenerator] __init__ å®Œæˆã€‚ ---", flush=True)
    
    # ... çœç•¥å…¶ä»–æ²’æœ‰è®Šå‹•çš„æ–¹æ³•ï¼Œä»¥ä¿æŒç°¡æ½” ...
    # æ‚¨å¯ä»¥åªä¿®æ”¹ _process_image æ–¹æ³•ï¼Œæˆ–è€…ç›´æ¥ç”¨é€™æ•´æ®µè¦†è“‹
    
    def _load_original_image(self):
        original_image_config = self.config.get('original_image', {})
        if isinstance(original_image_config, dict):
            original_image_path = original_image_config.get('path')
            if original_image_path and os.path.exists(original_image_path):
                return Image.open(original_image_path), os.path.splitext(os.path.basename(original_image_path))[0]
        return None, None

    def _prepare_prompt_for_api(self):
        from src.utils.prompts import get_default_action_dict, get_default_expression_dict
        if self.original_image is None:
            action_dict, expression_dict = get_default_action_dict(), get_default_expression_dict()
            action, expression = action_dict.get(self.action_key, "standing"), expression_dict.get(self.expression_key, "smiling")
            base_prompt = "a cartoon mushroom character with a light blue mushroom cap with white dots, eyes and mouth on its body, yellow feet"
            self.prompt = f"{base_prompt}, {action}, {expression}, consistent proportions, symmetrical features"

    def _generate_image_result(self, steps, generator):
        # é™¤éŒ¯ï¼šå°å‡º init_image æ˜¯å¦æœ‰è¢«ä½¿ç”¨
        print(f"[DEBUG] init_image å‚³å…¥: {self.original_image is not None}")
        print(f"[DEBUG] prompt: {self.prompt}")
        print(f"[DEBUG] negative_prompt: {self.negative_prompt}")
        return self.pipe(
            prompt=self.prompt,
            negative_prompt=self.negative_prompt,
            num_inference_steps=steps,
            height=self.height,
            width=self.width,
            guidance_scale=self.guidance_scale,
            init_image=self.original_image,
            strength=self.strength,
            num_images_per_prompt=1,
            generator=generator
        )

    def _extract_image_from_result(self, result):
        image = result.images[0] if hasattr(result, "images") else result[0]
        if image is None: raise ValueError("ç”Ÿæˆçš„åœ–åƒç‚º None")
        return image

    def _process_image(self, image):
        """ğŸš€ è¨˜æ†¶é«”å„ªåŒ–ç‰ˆæœ¬çš„åœ–åƒå»èƒŒè™•ç†"""
        print("--- [ImageGenerator] æ­£åœ¨è™•ç†åœ–åƒå»èƒŒ... ---", flush=True)
        
        # ä½¿ç”¨å…±äº«çš„ rembg sessionï¼Œé¿å…é‡è¤‡è¼‰å…¥æ¨¡å‹
        if ImageGenerator._rembg_session is None:
            from rembg import new_session
            print("--- [ImageGenerator] åˆå§‹åŒ– rembg session... ---", flush=True)
            ImageGenerator._rembg_session = new_session('u2net')  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
        
        from rembg import remove
        
        # ä½¿ç”¨ BytesIO æ¸›å°‘è¨˜æ†¶é«”è¤‡è£½
        with BytesIO() as input_buffer:
            # å°‡åœ–åƒä¿å­˜åˆ°è¨˜æ†¶é«”ç·©è¡å€
            image.save(input_buffer, format="PNG")
            input_buffer.seek(0)
            
            # ä½¿ç”¨ session é€²è¡Œå»èƒŒ
            result = remove(input_buffer.getvalue(), session=ImageGenerator._rembg_session)
            
            # è™•ç†è¿”å›çµæœ
            if isinstance(result, bytes):
                processed_image = Image.open(BytesIO(result))
            else:
                # å¦‚æœè¿”å›çš„æ˜¯ PIL Image æˆ–å…¶ä»–æ ¼å¼
                processed_image = result
        
        print("--- [ImageGenerator] åœ–åƒå»èƒŒå®Œæˆã€‚ ---", flush=True)
        return processed_image

    def _close_images(self, *images):
        """å¼·åŒ–çš„åœ–åƒè¨˜æ†¶é«”æ¸…ç† (æ”¯æ´ CUDA/MPS/CPU)"""
        for img in images:
            if isinstance(img, Image.Image):
                img.close()
        
        # å¼·åˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # æ¸…ç† GPU å¿«å– (å¦‚æœå¯ç”¨)
        if torch.cuda.is_available() and torch.cuda.device_count() > 0:
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            # Mac M1 MPS è¨˜æ†¶é«”æ¸…ç†
            torch.mps.empty_cache()
        # CPU ç’°å¢ƒä¸éœ€è¦ç‰¹æ®Šçš„å¿«å–æ¸…ç†
        
    def generate_single_image_api(self, steps, output_dir):
        """ğŸš€ è¨˜æ†¶é«”å„ªåŒ–ç‰ˆæœ¬çš„åœ–åƒç”Ÿæˆ"""
        image = None
        output_img = None
        result = None
        
        try:
            # ç”Ÿæˆå‰æ¸…ç†è¨˜æ†¶é«”å’Œæª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
            if torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
                print(f"ğŸ” ç”Ÿæˆå‰ CUDA è¨˜æ†¶é«”ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                torch.mps.empty_cache()
                print(f"ğŸ” ç”Ÿæˆå‰ MPS è¨˜æ†¶é«”ä½¿ç”¨: {torch.mps.current_allocated_memory()/1024**3:.2f}GB")
            else:
                print("ğŸ” ç”Ÿæˆå‰è¨˜æ†¶é«”æ¸…ç†å®Œæˆ (CPU æ¨¡å¼)")
            
            self._prepare_prompt_for_api()
            random_seed = int(time.time())
            generator = torch.Generator(device="cuda" if torch.cuda.is_available() else "cpu").manual_seed(random_seed)
            
            # ç”Ÿæˆåœ–åƒ
            result = self._generate_image_result(steps, generator)
            image = self._extract_image_from_result(result)
            
            # ç«‹å³æ¸…ç†ç”Ÿæˆçµæœ
            del result
            if torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
                print(f"ğŸ” åœ–åƒç”Ÿæˆå¾Œ CUDA è¨˜æ†¶é«”ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                torch.mps.empty_cache()
                print(f"ğŸ” åœ–åƒç”Ÿæˆå¾Œ MPS è¨˜æ†¶é«”ä½¿ç”¨: {torch.mps.current_allocated_memory()/1024**3:.2f}GB")
            else:
                print("ğŸ” åœ–åƒç”Ÿæˆå¾Œè¨˜æ†¶é«”æ¸…ç†å®Œæˆ (CPU æ¨¡å¼)")
            
            # è™•ç†åœ–åƒ (å»èƒŒ)
            output_img = self._process_image(image)
            
            # ç«‹å³æ¸…ç†åŸå§‹åœ–åƒ
            if image:
                image.close()
                del image
                image = None
            
            timestamp = int(time.time())
            filename = f"{self.weight_name}_{self.action_key}_{self.expression_key}_{timestamp}_transparent.png"
            full_path = os.path.join(output_dir, filename)
            
            # ä¿®æ­£ output_img å¯èƒ½ç‚º ndarray æˆ– bytes çš„æƒ…æ³
            if isinstance(output_img, np.ndarray):
                output_img = Image.fromarray(output_img)
            elif isinstance(output_img, bytes):
                output_img = Image.open(BytesIO(output_img))
            
            # å„²å­˜åœ–åƒ
            output_img.save(full_path)
            print(f"âœ… API å·²ç”Ÿæˆåœ–åƒï¼š{full_path}", flush=True)
            
            # æ¸…ç†è¼¸å‡ºåœ–åƒ
            if output_img:
                output_img.close()
                del output_img
                output_img = None
            
            # æœ€çµ‚è¨˜æ†¶é«”æ¸…ç†
            gc.collect()
            if torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
                print(f"ğŸ” å®Œæˆå¾Œ CUDA è¨˜æ†¶é«”ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                torch.mps.empty_cache()
                print(f"ğŸ” å®Œæˆå¾Œ MPS è¨˜æ†¶é«”ä½¿ç”¨: {torch.mps.current_allocated_memory()/1024**3:.2f}GB")
            else:
                print("ğŸ” å®Œæˆå¾Œè¨˜æ†¶é«”æ¸…ç†å®Œæˆ (CPU æ¨¡å¼)")
            
            return os.path.join(f"{self.weight_name}", str(steps), filename)
            
        except Exception as e:
            print(f"!!!!!!!! âš ï¸ API ç”Ÿæˆåœ–ç‰‡æ™‚å‡ºéŒ¯: {e} !!!!!!!!", file=sys.stderr, flush=True)
            # éŒ¯èª¤æ™‚ä¹Ÿè¦æ¸…ç†è¨˜æ†¶é«”
            self._close_images(image, output_img)
            if result:
                del result
            gc.collect()
            if torch.cuda.is_available() and torch.cuda.device_count() > 0:
                torch.cuda.empty_cache()
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                torch.mps.empty_cache()
            raise e

    def generate_images(self):
        """æ‰¹æ¬¡ç”Ÿæˆåœ–åƒ (ä¸»ç¨‹å¼ä½¿ç”¨)"""
        print("--- [ImageGenerator] é–‹å§‹æ‰¹æ¬¡ç”Ÿæˆåœ–åƒ... ---", flush=True)
        
        # ç²å–æ¨ç†é…ç½®
        inference_configs = self.config.get('inference_config', [{'steps': 50, 'num_images': 1}])
        
        for config in inference_configs:
            steps = config.get('steps', 50)
            num_images = config.get('num_images', 1)
            
            print(f"--- [ImageGenerator] ç”Ÿæˆ {num_images} å¼µåœ–åƒï¼Œæ­¥æ•¸: {steps} ---", flush=True)
            
            for i in range(num_images):
                try:
                    # æº–å‚™è¼¸å‡ºç›®éŒ„ (èˆ‡ API ä¿æŒä¸€è‡´)
                    import os
                    output_dir = f"outputs/{self.weight_name}/{steps}"
                    os.makedirs(output_dir, exist_ok=True)
                    
                    # ç”Ÿæˆåœ–åƒ
                    result_path = self.generate_single_image_api(steps, output_dir)
                    print(f"âœ… å·²ç”Ÿæˆç¬¬ {i+1}/{num_images} å¼µåœ–åƒ")
                    
                except Exception as e:
                    print(f"âš ï¸ ç”Ÿæˆç¬¬ {i+1} å¼µåœ–åƒæ™‚å‡ºéŒ¯: {e}")
                    continue
        
        print("--- [ImageGenerator] æ‰¹æ¬¡ç”Ÿæˆå®Œæˆã€‚ ---", flush=True)

# æˆ‘å€‘ç”šè‡³å¯ä»¥åœ¨ class å®šç¾©ä¹‹å¾Œä¹ŸåŠ ä¸Š printï¼Œç¢ºä¿æ•´å€‹æª”æ¡ˆéƒ½åŸ·è¡Œå®Œç•¢
print("--- [ImageGenerator] æ¨¡å¡Šå·²æˆåŠŸè¢«å®šç¾©ï¼Œæ‰€æœ‰é ‚å±¤ä»£ç¢¼åŸ·è¡Œå®Œç•¢ã€‚ ---", flush=True)